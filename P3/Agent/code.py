import numpy as np
import pandas as pd

# define files path
train_path = "./train.csv"
test_path = "./test.csv"

# read csv file
train_df = pd.read_csv(train_path)
test_df = pd.read_csv(test_path)

# remove id
train_df.drop(columns=['id'], inplace=True)
test_ids = test_df['id']
test_df.drop(columns=['id'], inplace=True)

print(f"shape of train: {train_df.shape}")
print(f"shape of test: {test_df.shape}")
print(f"columns names: {train_df.columns[:].tolist()}")

def apply_sr_features(df):
    # é¿å…é™¤ä»¥é›¶
    eps = 1e-6
    
    # 1. å…»åˆ†æ¯”ä¾‹å› å­ (ç»å…¸çš„å†œå­¦æŒ‡æ ‡)
    df['N_P_ratio'] = df['Nitrogen'] / (df['Phosphorous'] + eps)
    df['N_K_ratio'] = df['Nitrogen'] / (df['Potassium'] + eps)
    df['P_K_ratio'] = df['Phosphorous'] / (df['Potassium'] + eps)
    
    # 2. ç¯å¢ƒäº¤äº’å› å­
    df['Temp_Hum_Index'] = df['Temparature'] * df['Humidity']
    df['Moisture_Hum_Ratio'] = df['Moisture'] / (df['Humidity'] + eps)
    
    # 3. å…»åˆ†æ€»é‡
    df['Total_NPK'] = df['Nitrogen'] + df['Potassium'] + df['Phosphorous']
    
    # 4. å…»åˆ†é›†ä¸­åº¦ (SR å¸¸ç”¨éçº¿æ€§ç»„åˆ)
    df['N_interaction'] = df['Nitrogen'] * df['Moisture']

    # [agent]ä»£ç 
    
    
    return df

# å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†åŒæ—¶åº”ç”¨
train_df = apply_sr_features(train_df)
test_df = apply_sr_features(test_df)

# è·å–æ‰€æœ‰å”¯ä¸€çš„è‚¥æ–™åç§°
unique_fertilizers = train_df['Fertilizer Name'].unique()

print(f"å…±æœ‰ {len(unique_fertilizers)} ç§è‚¥æ–™ï¼š")
print(unique_fertilizers)

# target variable y
if 'Fertilizer Name' in train_df.columns:
    
    y = train_df['Fertilizer Name'].map({'28-28':0, '17-17-17':1, '10-26-26':2, 'DAP':3, '20-20':4, '14-35-14':5, 'Urea':6})
    train_df.drop(columns=['Fertilizer Name'], inplace=True)

# label encoding
from sklearn.preprocessing import LabelEncoder

cat_cols = train_df.select_dtypes(include=['object']).columns

for col in cat_cols:
    # fill N/A
    train_df[col] = train_df[col].astype(str).fillna('missing')
    test_df[col] = test_df[col].astype(str).fillna('missing')
    
    le = LabelEncoder()

    # get all labels
    full_data = pd.concat([train_df[col], test_df[col]], axis=0)
    le.fit(full_data)
    
    train_df[col] = le.transform(train_df[col])
    test_df[col] = le.transform(test_df[col])

print("Label Encoding finish")

# split train and val
from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(
    train_df, y, test_size=0.2, random_state=42, stratify=y
)

print(f"shape of X_train: {X_train.shape}")
print(f"shape of X_val: {X_val.shape}")

import optuna
import lightgbm as lgb
import numpy as np

# 1. å®šä¹‰ MAP@3 è®¡ç®—å‡½æ•°
def mapk(actual, predicted_probs, k=3):
    """
    actual: çœŸå®æ ‡ç­¾çš„æ•°ç»„ (n_samples,)
    predicted_probs: æ¨¡å‹è¾“å‡ºçš„æ¦‚ç‡çŸ©é˜µ (n_samples, n_classes)
    """
    scores = []
    # è·å–æ¦‚ç‡æœ€é«˜çš„å‰ k ä¸ªç´¢å¼•
    top_k_indices = np.argsort(-predicted_probs, axis=1)[:, :k]
    
    for a, p in zip(actual, top_k_indices):
        score = 0.0
        for i, pred in enumerate(p):
            if pred == a:
                score = 1.0 / (i + 1)
                break
        scores.append(score)
    return np.mean(scores)

def objective_lgb(trial):
    # --- [GA éƒ¨åˆ†: ç‰¹å¾é€‰æ‹©å¼€å…³] ---
    all_features = X_train.columns.tolist()
    # ä¸ºæ¯ä¸€ä¸ªç‰¹å¾åˆ›å»ºä¸€ä¸ªå¸ƒå°”å¼€å…³
    selected_features = [
        col for col in all_features 
        if trial.suggest_categorical(f'use_{col}', [True, False])
    ]
    
    # ç¡®ä¿è‡³å°‘é€‰æ‹©äº†ä¸€ä¸ªç‰¹å¾ï¼Œå¦åˆ™è¯¥ trial æ— æ•ˆ
    if len(selected_features) == 0:
        return 0

    # ä½¿ç”¨é€‰ä¸­çš„ç‰¹å¾å­é›†
    X_tr_sub = X_train[selected_features]
    X_va_sub = X_val[selected_features]

    param = {
        'objective': 'multiclass',
        'num_class': 7,
        'metric': 'multi_logloss',
        'verbosity': -1,
        'device': 'gpu', # å°æ•°æ®é›†å»ºè®®ç”¨ cpuï¼Œå‡å°‘æ•°æ®æ¬è¿æ—¶é—´
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),
        'num_leaves': trial.suggest_int('num_leaves', 20, 64),
        'max_depth': trial.suggest_int('max_depth', 3, 8),
        'n_estimators': 300, # é…åˆæ—©åœå¯ä»¥ä½¿ç”¨æ›´å¤§çš„å€¼
        'random_state': 42
    }

    model = lgb.LGBMClassifier(**param)
    
    # å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ Numpy æ•°ç»„è®­ç»ƒï¼Œå¹¶åŠ å…¥ eval_set å¼€å¯æ—©åœæé€Ÿ
    model.fit(
        X_tr_sub, y_train,
        eval_set=[(X_va_sub, y_val)],
        callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=False)]
    )
    
    probs = model.predict_proba(X_va_sub)
    score = mapk(y_val, probs, k=3)
    
    return score

# 6. å¼€å§‹ä¼˜åŒ–
study_lgb = optuna.create_study(direction='maximize')
study_lgb.optimize(objective_lgb, n_trials=30)

print("æœ€ä¼˜å‚æ•°: ", study_lgb.best_params)
print("æœ€é«˜ MAP@3: ", study_lgb.best_value)

import json
import numpy as np
import pandas as pd
import lightgbm as lgb

# --- 1. ä» Optuna ç»“æœä¸­æå–è¢«é€‰ä¸­çš„ç‰¹å¾å ---
best_params_all = study_lgb.best_params

# æ‰¾å‡ºæ‰€æœ‰å€¼ä¸º True çš„ 'use_xxx' å‚æ•°ï¼Œå¹¶è¿˜åŸæˆåŸå§‹åˆ—å
selected_features = [
    k.replace('use_', '') for k, v in best_params_all.items() 
    if k.startswith('use_') and v is True
]

print(f"âœ… æœ€ç»ˆæ¨¡å‹é€‰ä¸­çš„ç‰¹å¾ ({len(selected_features)}ä¸ª):")
print(selected_features)

# --- 2. æå–çœŸæ­£çš„æ¨¡å‹è¶…å‚æ•° (å‰”é™¤ use_ å¼€å¤´çš„å¼€å…³) ---
final_model_params = {
    k: v for k, v in best_params_all.items() 
    if not k.startswith('use_')
}
final_model_params.update({
    'objective': 'multiclass',
    'num_class': 7,
    'metric': 'multi_logloss',
    'verbosity': -1,
    'device': 'cpu'  # æœ€ç»ˆé¢„æµ‹é˜¶æ®µ CPU è¶³å¤Ÿå¿«ä¸”ç¨³
})

# --- 3. å‡†å¤‡å…¨é‡è®­ç»ƒæ•°æ® (åªåŒ…å«é€‰ä¸­çš„ç‰¹å¾) ---
# å‡è®¾ X æ˜¯åŒ…å«æ‰€æœ‰ SR ç‰¹å¾çš„å®Œæ•´è®­ç»ƒ DataFrame
X_full = pd.concat([X_train, X_val])[selected_features]
y_full = pd.concat([y_train, y_val])

# --- 4. æœ€ç»ˆå…¨é‡è®­ç»ƒ ---
print("æ­£åœ¨è¿›è¡Œæœ€ç»ˆå…¨é‡è®­ç»ƒ...")
final_model = lgb.LGBMClassifier(**final_model_params)
final_model.fit(X_full, y_full)

# --- 5. å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ (å…³é”®ï¼šåªå–é€‰ä¸­çš„ç‰¹å¾) ---
print("æ­£åœ¨ç”Ÿæˆé¢„æµ‹ç»“æœ...")
# è¿™é‡Œçš„ test_df å¿…é¡»ä¹Ÿè¦ç”¨ selected_features è¿‡æ»¤
test_df_filtered = test_df[selected_features]
probs = final_model.predict_proba(test_df_filtered)

# --- 6. ç”Ÿæˆæäº¤æ–‡ä»¶ ---
top3_idx = np.argsort(-probs, axis=1)[:, :3]
inv_map = {0:'28-28', 1:'17-17-17', 2:'10-26-26', 3:'DAP', 4:'20-20', 5:'14-35-14', 6:'Urea'}

final_preds = [" ".join([inv_map[idx] for idx in row]) for row in top3_idx]

submission = pd.DataFrame({
    'id': test_ids,
    'Fertilizer Name': final_preds
})

submission.to_csv('submission.csv', index=False)
print("ğŸš€ æäº¤æ–‡ä»¶ submission.csv å·²æˆåŠŸç”Ÿæˆï¼")
display(submission.head())