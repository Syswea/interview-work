import pandas as pd
import numpy as np
import re
from typing import TypedDict, List, Optional
from sklearn.model_selection import train_test_split
from lightgbm import LGBMClassifier
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END

# ==========================================
# 1. åˆå§‹åŒ–
# ==========================================
llm = ChatOpenAI(
    base_url="http://127.0.0.1:1234/v1",
    api_key="not-needed",
    model_name="local-model",
    temperature=0.1
)

# è¯»å–æ•°æ® (è¯·ç¡®ä¿ train.csv åœ¨ç›®å½•ä¸‹)
df_train_raw = pd.read_csv('./P3/train.csv')

class AgentState(TypedDict):
    code: str
    current_score: float
    feedback: str
    iteration_count: int
    is_fix_needed: bool  # æ–°å¢ï¼šæ ‡è®°æ˜¯å¦éœ€è¦çº é”™
    best_code: str

# ==========================================
# 2. æ ¸å¿ƒå‡½æ•°
# ==========================================

def map3_score(y_true, y_probs, labels):
    top3_idx = np.argsort(y_probs, axis=1)[:, -3:][:, ::-1]
    score = 0.0
    y_true_vals = y_true.values if hasattr(y_true, 'values') else y_true
    for i, true_val in enumerate(y_true_vals):
        prediction_list = labels[top3_idx[i]]
        for j, pred in enumerate(prediction_list):
            if pred == true_val:
                score += 1.0 / (j + 1)
                break
    return score / len(y_true)

def feature_engineer_node(state: AgentState):
    # æ ¹æ®æ˜¯å¦æŠ¥é”™è°ƒæ•´ Prompt
    error_prefix = ""
    if state.get("is_fix_needed", False):
        error_prefix = f"ã€ç´§æ€¥çº é”™ã€‘ä½ ä¸Šä¸€è½®çš„ä»£ç æŠ¥é”™äº†ï¼š{state['feedback']}\nè¯·ä¿®æ­£é”™è¯¯ï¼"
    
    prompt = f"""ä½ æ˜¯ä¸€ä¸ª Kaggle ä¸“å®¶ã€‚ä»»åŠ¡ï¼šç¼–å†™ Python å‡½æ•° `transform_data(df)`ã€‚
åŸå§‹å­—æ®µï¼šTemparature, Humidity, Moisture, Soil Type, Crop Type, Nitrogen, Potassium, Phosphorous
{error_prefix}
å½“å‰æœ€é«˜åˆ†ï¼š{state['current_score']}
è¦æ±‚ï¼š
1. åŒ…å« import pandas as pd å’Œ import numpy as npã€‚
2. å¿…é¡»å¤„ç†åŸå§‹ç‰¹å¾ï¼Œè¿”å›åŒ…å« 3 ä¸ªä»¥ä¸Šæ–°ç‰¹å¾çš„ DataFrameã€‚
3. åªè¾“å‡ºä»£ç ï¼Œä¸è¦ä»»ä½•è§£é‡Šï¼Œä¸è¦åŒ…å« Markdown æ ‡ç­¾ã€‚
"""
    response = llm.invoke(prompt)
    clean_code = re.sub(r'```python|```', '', response.content).strip()
    return {"code": clean_code}

def evaluation_node(state: AgentState):
    global df_train_raw
    try:
        # æ‰§è¡Œ LLM ç”Ÿæˆçš„ä»£ç 
        exec_globals = {"pd": pd, "np": np}
        exec(state['code'], exec_globals)
        transform_fn = exec_globals['transform_data']
        
        # æ•°æ®å¤„ç†
        df = transform_fn(df_train_raw.copy())
        
        # ç®€å•å¤„ç†åˆ†ç±»å˜é‡
        for col in df.select_dtypes(include=['object']).columns:
            if col != 'Fertilizer Name':
                df[col] = df[col].astype('category').cat.codes
        
        X = df.drop(['id', 'Fertilizer Name'], axis=1, errors='ignore')
        y = df['Fertilizer Name']
        
        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
        
        model = LGBMClassifier(n_estimators=100, learning_rate=0.1, verbose=-1)
        model.fit(X_train, y_train)
        
        score = map3_score(y_val, model.predict_proba(X_val), model.classes_)
        
        # æˆåŠŸè¿è¡Œï¼šä¸è®¡å…¥çº é”™ï¼Œå¢åŠ è¿­ä»£è®¡æ•°
        new_best_code = state['best_code']
        if score > state['current_score']:
            new_best_code = state['code']
            
        return {
            "current_score": max(score, state['current_score']),
            "feedback": f"è¿è¡ŒæˆåŠŸï¼Œå¾—åˆ†: {score:.4f}",
            "is_fix_needed": False,
            "iteration_count": state['iteration_count'] + 1,
            "best_code": new_best_code
        }
    except Exception as e:
        # è¿è¡Œå¤±è´¥ï¼šæ ‡è®°éœ€è¦çº é”™ï¼Œä¸å¢åŠ  iteration_count
        return {
            "feedback": f"âŒ è¿è¡ŒæŠ¥é”™: {str(e)}",
            "is_fix_needed": True
        }

# ==========================================
# 3. è·¯ç”±ä¸æµç¨‹æ„å»º
# ==========================================

def should_continue(state: AgentState):
    # 1. ä¼˜å…ˆå¤„ç†çº é”™
    if state.get("is_fix_needed", False):
        print(f"   >>> å‘ç°é”™è¯¯ï¼Œæ‰“å›ä¿®æ­£...")
        return "engineer"
    # 2. åˆ¤æ–­æ˜¯å¦å®Œæˆ
    if state["iteration_count"] >= 5:
        return END
    # 3. ç»§ç»­æ–°ä¸€è½®æ¢ç´¢
    return "engineer"

workflow = StateGraph(AgentState)
workflow.add_node("engineer", feature_engineer_node)
workflow.add_node("evaluate", evaluation_node)

workflow.set_entry_point("engineer")
workflow.add_edge("engineer", "evaluate")
# åªæ·»åŠ ä¸€æ¬¡è·¯ç”±
workflow.add_conditional_edges("evaluate", should_continue, {
    "engineer": "engineer",
    END: END
})

app = workflow.compile()

# ==========================================
# 4. æ‰§è¡Œ
# ==========================================

initial_state = {
    "code": "",
    "current_score": 0.0,
    "feedback": "å¼€å§‹æ¢ç´¢",
    "iteration_count": 0,
    "is_fix_needed": False,
    "best_code": ""
}

print("ğŸš€ Agent å¼€å§‹å·¥ä½œï¼Œæ­£åœ¨å®æ—¶æµå¼è¾“å‡ºèŠ‚ç‚¹çŠ¶æ€...\n")

# ä½¿ç”¨ stream æ¨¡å¼æŸ¥çœ‹æ¯ä¸€ä¸ªæ­¥éª¤
for output in app.stream(initial_state):
    # output çš„æ ¼å¼æ˜¯ { "èŠ‚ç‚¹åç§°": { "çŠ¶æ€æ›´æ–°å†…å®¹" } }
    for node_name, state_update in output.items():
        print(f"æ ‡æ³¨èŠ‚ç‚¹: [{node_name}]")
        
        if node_name == "engineer":
            print("ğŸ“ LLM ç”Ÿæˆçš„ä»£ç ç‰‡æ®µ (å‰ 100 å­—ç¬¦):")
            print(state_update['code'][:100] + "...")
            
        elif node_name == "evaluate":
            print(f"ğŸ“Š è¯„ä¼°ç»“æœ: {state_update.get('feedback', 'æ— åé¦ˆ')}")
            print(f"ğŸ† å½“å‰æœ€ä½³åˆ†æ•°: {state_update.get('current_score', 0.0)}")
            
        print("-" * 40)

# æœ€åæ‰“å°æœ€ç»ˆç»“æœ
final_state = app.get_state(config={}).values # è·å–æœ€åçŠ¶æ€ï¼ˆå–å†³äºå…·ä½“ç‰ˆæœ¬ï¼Œå¯ç”¨ invoke çš„ç»“æœä»£æ›¿ï¼‰