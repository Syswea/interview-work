以下是针对大模型的开发工作的细致分类及其对应的技术栈和能力要求：

1. 应用开发方向 (LLM Application Development)
这是目前需求量最大、落地最快的方向。核心是利用现有的大模型能力，通过工程化手段解决具体业务问题。

核心分类：

RAG (检索增强生成)： 给大模型外挂一个“私人知识库”。

Agent (智能体)： 让模型学会使用工具（如搜索、发邮件、跑代码）来完成复杂任务。

多模态应用： 结合图像、语音与文本的跨模态交互。

技术栈：

框架： LangChain, LlamaIndex, LangGraph (用于复杂 Agent 编排)。

向量数据库： Pinecone, Milvus, Weaviate, Qdrant。

提示工程： Chain-of-Thought (CoT), ReAct 模式, Prompt 调优。

能力要求：

熟悉模型 API 的调用与流式处理。

具备业务拆解能力，能将复杂任务转化为模型可执行的步骤。

2. 模型工程方向 (Model Engineering & Fine-tuning)
侧重于对现有基座模型进行定制化改造，使其更适应特定行业或特定任务。

核心分类：

微调 (Fine-tuning)： 使用行业数据对模型进行增量训练。

对齐 (Alignment)： 通过 RLHF 或 DPO 让模型回答更符合人类价值观。

量化压缩： 为了在低成本显卡上跑大模型，对模型进行“瘦身”。

技术栈：

微调工具： Hugging Face Transformers, LLaMA-Factory, DeepSpeed, Megatron-LM。

高效微调技术： LoRA, QLoRA, P-Tuning。

数学基础： 线性代数、概率论、深度学习底层原理。

能力要求：

掌握 GPU 算力分配与显存优化。

能够处理训练过程中的过拟合与遗忘问题。

3. 数据工程方向 (Data Engineering for LLM)
在 AI 界有句话：“数据决定了模型的上限”。这个方向负责为模型提供高质量的“燃料”。

核心分类：

清洗与标注： 过滤网页中的垃圾信息，进行高质量的人工标注。

合成数据 (Synthetic Data)： 用大模型生成大模型所需的训练数据。

评估工程： 构建评测集，用 “LLM-as-a-judge” 技术自动化评估应用效果。

技术栈：

数据流工具： Apache Spark, Ray (大规模并行计算)。

评测框架： RAGAS (专门评测 RAG), Giskard, Deepchecks。

能力要求：

极强的数据清洗能力（正则表达式、NLP 预处理）。

具备统计学眼光，能识别数据中的偏见和噪声。

4. 运维与部署方向 (LLMOps / Infra)
确保模型能以高并发、低延迟、低成本的方式跑在生产环境。

核心分类：

推理加速： 提高模型生成文本的速度。

监控与可观测性： 监控模型是否出现“幻觉”或报错。

成本控制： 计算 Token 消耗，优化模型调用链路。

技术栈：

推理引擎： vLLM, Text Generation Inference (TGI), Ollama, NVIDIA Triton。

云原生： Docker, Kubernetes (K8s), KubeRay。

量化格式： GGUF, AWQ, GPTQ。

能力要求：

熟悉 Linux 系统与 NVIDIA 驱动管理。

具备传统后端高并发架构经验。